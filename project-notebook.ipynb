{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e031184a68fec92f",
   "metadata": {},
   "source": [
    "Adding all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738013728e603e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:26.353445Z",
     "start_time": "2024-04-17T01:32:12.835034Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import TruePositives, TrueNegatives, FalsePositives, FalseNegatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8d1867f50841e",
   "metadata": {},
   "source": [
    "Make sure you have your kaggle.json in ~/.kaggle folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc6ebb016effd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:12.833033Z",
     "start_time": "2024-04-17T01:29:34.099498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Downloading the data to the Google Colab\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Coping the kaggle API to the Google Colab\n",
    "# os.environ['KAGGLE_CONFIG_DIR'] = path_API_autentification_token\n",
    "\n",
    "# Downloading the data\n",
    "!poetry run kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
    "# or\n",
    "# !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
    "# or\n",
    "# !python -m kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "# Unzziping the data and storing into /tmp\n",
    "zip_ref = zipfile.ZipFile('chest-xray-pneumonia.zip', 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9981a0c3c15f5df1",
   "metadata": {},
   "source": [
    "Fix the distribution of the validation set. Currently there are only 16 images in the validation set. We will combine everything and then split it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb8439653c371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/tmp/chest_xray/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "dataset_path= '/tmp/chest_xray/'\n",
    "new_dataset_path = '/tmp/chest_xray_new/'\n",
    "if not os.path.exists(new_dataset_path):\n",
    "   for split in ['train', 'val', 'test']:\n",
    "       for cls in ['NORMAL', 'PNEUMONIA']:\n",
    "           os.makedirs(f'{new_dataset_path}/{split}/{cls}', exist_ok=True)\n",
    "\n",
    "   for cls in ['NORMAL', 'PNEUMONIA']:\n",
    "       all_files = []\n",
    "       for split in ['train', 'val', 'test']:\n",
    "           source_folder = f'{dataset_path}/{split}/{cls}'\n",
    "           files = os.listdir(source_folder)\n",
    "           all_files.extend([(file, source_folder) for file in files])\n",
    "\n",
    "       random.shuffle(all_files)\n",
    "\n",
    "       train_files = all_files[:int(len(all_files)*0.8)]\n",
    "       val_files = all_files[int(len(all_files)*0.8):int(len(all_files)*0.9)]\n",
    "       test_files = all_files[int(len(all_files)*0.9):]\n",
    "\n",
    "       for file, source_folder in train_files:\n",
    "           dest = f'{new_dataset_path}/train/{cls}/{file}'\n",
    "           shutil.copy(f'{source_folder}/{file}', dest)\n",
    "\n",
    "       for file, source_folder in val_files:\n",
    "           dest = f'{new_dataset_path}/val/{cls}/{file}'\n",
    "           shutil.copy(f'{source_folder}/{file}', dest)\n",
    "\n",
    "       for file, source_folder in test_files:\n",
    "           dest = f'{new_dataset_path}/test/{cls}/{file}'\n",
    "           shutil.copy(f'{source_folder}/{file}', dest) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5d44793947f2d",
   "metadata": {},
   "source": [
    "Splitting the data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0723e8608ef781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:26.369387Z",
     "start_time": "2024-04-17T01:32:26.354388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the paths of the directories that were unzipped\n",
    "train_dir = '/tmp/chest_xray_new/train'\n",
    "val_dir = '/tmp/chest_xray_new/val'\n",
    "test_dir = '/tmp/chest_xray_new/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cc929f8849a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:26.385390Z",
     "start_time": "2024-04-17T01:32:26.371387Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define image sizes\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b316ff9451b1ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:33.381574Z",
     "start_time": "2024-04-17T01:32:26.387391Z"
    }
   },
   "outputs": [],
   "source": [
    "#import images into dataframes\n",
    "train_df = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    color_mode = 'grayscale',\n",
    "    image_size = (img_height,img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "val_df = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    color_mode = 'grayscale',\n",
    "    image_size = (img_height,img_width),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_df = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    color_mode = 'grayscale',\n",
    "    image_size = (img_height,img_width),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945fec53669777b6",
   "metadata": {},
   "source": [
    "Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1c26cd14055ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:44.611867Z",
     "start_time": "2024-04-17T01:32:33.383573Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "test_labels = []\n",
    "val_labels = []\n",
    "\n",
    "for images, labels in train_df.unbatch():\n",
    "  train_labels.append(labels.numpy())\n",
    "\n",
    "for images, labels in test_df.unbatch():\n",
    "  test_labels.append(labels.numpy())\n",
    "\n",
    "for images, labels in val_df.unbatch():\n",
    "  val_labels.append(labels.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d364ca4bd646392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:44.657870Z",
     "start_time": "2024-04-17T01:32:44.613867Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Count values of instances per label in train dataset\\n\")\n",
    "print(pd.DataFrame(np.unique(train_labels, return_counts = True), index=['Label', 'count'], columns=['Normal','Pneumonia']))\n",
    "print(\"\\n\\nCount values of instances per label in test dataset\\n\")\n",
    "print(pd.DataFrame(np.unique(test_labels, return_counts = True), index=['Label', 'count'], columns=['Normal','Pneumonia']))\n",
    "print(\"\\n\\nCount values of instances per label in validation dataset\\n\")\n",
    "print(pd.DataFrame(np.unique(val_labels, return_counts = True), index=['Label', 'count'], columns=['Normal','Pneumonia']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afcaaadd0f41c6b",
   "metadata": {},
   "source": [
    "Image visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b953e1c0658e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:52.120644Z",
     "start_time": "2024-04-17T01:32:49.667580Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_df.take(1):\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.squeeze(images[i].numpy().astype(\"uint8\")))\n",
    "        plt.title(train_df.class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3bd51a17df525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:32:57.825282Z",
     "start_time": "2024-04-17T01:32:57.809315Z"
    }
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_df = train_df.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_df = val_df.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_df = test_df.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a7d1dcaeb1b2e0",
   "metadata": {},
   "source": [
    "Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2ec591dfaa473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228ec60ab35790bf",
   "metadata": {},
   "source": [
    "Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7315b81bb7887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T01:33:36.433736Z",
     "start_time": "2024-04-17T01:33:33.065894Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "# ploting accuracy and validation accuracy\n",
    "plt.subplot(1,2,1)\n",
    "sns.lineplot(x=history.epoch, y=history.history['accuracy'], color='grey', label='Train Accuracy')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_accuracy'], color='green', label='Val Accuracy')\n",
    "plt.title('Accuracy on train vs test')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# plotting loss and validation loss (sparse categorical crossentropy)\n",
    "plt.subplot(1,2,2)\n",
    "sns.lineplot(x=history.epoch, y=history.history['loss'], color='grey', label='Train Loss')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_loss'], color='red', label='Val Loss')\n",
    "plt.title('Loss on train vs test')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b192de7d8928b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
